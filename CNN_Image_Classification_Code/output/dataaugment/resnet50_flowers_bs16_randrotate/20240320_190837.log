2024-03-20 19:08:38,257 - mmcls - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) [GCC 9.4.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 2080 Ti
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.8, V11.8.89
GCC: gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0
PyTorch: 1.13.1+cu117
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.14.1+cu117
OpenCV: 4.9.0
MMCV: 1.5.0
MMCV Compiler: n/a
MMCV CUDA Compiler: n/a
MMClassification: 0.15.0+3baa3c1
------------------------------------------------------------

2024-03-20 19:08:38,258 - mmcls - INFO - Distributed training: False
2024-03-20 19:08:38,425 - mmcls - INFO - Config:
model = dict(
    type='ImageClassifier',
    backbone=dict(
        type='ResNet',
        depth=50,
        num_stages=4,
        out_indices=(3, ),
        style='pytorch'),
    neck=dict(type='GlobalAveragePooling'),
    head=dict(
        type='LinearClsHead',
        num_classes=17,
        in_channels=2048,
        loss=dict(type='CrossEntropyLoss', loss_weight=1.0)))
dataset_type = 'Flowers'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='RandomResizedCrop', size=224),
    dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),
    dict(type='ColorJitter', brightness=0.4, contrast=0.4, saturation=0.4),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='ImageToTensor', keys=['img']),
    dict(type='ToTensor', keys=['gt_label']),
    dict(type='Collect', keys=['img', 'gt_label'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='Resize', size=(256, -1)),
    dict(type='CenterCrop', crop_size=224),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='ImageToTensor', keys=['img']),
    dict(type='Collect', keys=['img'])
]
data = dict(
    samples_per_gpu=16,
    workers_per_gpu=1,
    train=dict(
        type='Flowers',
        data_prefix='data/flowers/train',
        ann_file='data/flowers/meta/train.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='RandomResizedCrop', size=224),
            dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),
            dict(
                type='ColorJitter',
                brightness=0.4,
                contrast=0.4,
                saturation=0.4),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='ToTensor', keys=['gt_label']),
            dict(type='Collect', keys=['img', 'gt_label'])
        ]),
    val=dict(
        type='Flowers',
        data_prefix='data/flowers/val',
        ann_file='data/flowers/meta/val.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='Resize', size=(256, -1)),
            dict(type='CenterCrop', crop_size=224),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ]),
    test=dict(
        type='Flowers',
        data_prefix='data/flowers/test',
        ann_file='data/flowers/meta/test.txt',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='Resize', size=(256, -1)),
            dict(type='CenterCrop', crop_size=224),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ]))
evaluation = dict(interval=1, metric='accuracy')
optimizer = dict(type='SGD', lr=0.1, momentum=0.9, weight_decay=0.0001)
optimizer_config = dict(grad_clip=None)
lr_config = dict(policy='step', step=[100, 150])
runner = dict(type='EpochBasedRunner', max_epochs=200)
checkpoint_config = dict(interval=100)
log_config = dict(interval=100, hooks=[dict(type='TextLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
work_dir = 'output/dataaugment/resnet50_flowers_bs16_randrotate'
gpu_ids = range(0, 1)

2024-03-20 19:08:39,172 - mmcls - INFO - initialize ResNet with init_cfg [{'type': 'Kaiming', 'layer': ['Conv2d']}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]
2024-03-20 19:08:39,499 - mmcls - INFO - initialize LinearClsHead with init_cfg {'type': 'Normal', 'layer': 'Linear', 'std': 0.01}
Name of parameter - Initialization information

backbone.conv1.weight - torch.Size([64, 3, 7, 7]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.0.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.0.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.0.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.0.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.0.bn3.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in ResNet  

backbone.layer1.0.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.0.downsample.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.0.downsample.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.1.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.1.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.1.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.1.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.1.bn3.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in ResNet  

backbone.layer1.1.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.2.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.2.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.2.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.2.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.2.bn3.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in ResNet  

backbone.layer1.2.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.0.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.0.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.0.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in ResNet  

backbone.layer2.0.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.0.downsample.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.downsample.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.1.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in ResNet  

backbone.layer2.1.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.2.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.2.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.2.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.2.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.2.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in ResNet  

backbone.layer2.2.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.3.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.3.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.3.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.3.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.3.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in ResNet  

backbone.layer2.3.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.0.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet  

backbone.layer3.0.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.0.downsample.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.downsample.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.1.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet  

backbone.layer3.1.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.2.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.2.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.2.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.2.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.2.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet  

backbone.layer3.2.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.3.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.3.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.3.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.3.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.3.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet  

backbone.layer3.3.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.4.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.4.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.4.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.4.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.4.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet  

backbone.layer3.4.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.5.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.5.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.5.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.5.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.5.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet  

backbone.layer3.5.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.0.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.0.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.0.bn3.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in ResNet  

backbone.layer4.0.bn3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.0.downsample.1.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.downsample.1.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.1.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.1.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.1.bn3.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in ResNet  

backbone.layer4.1.bn3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.2.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.2.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.2.bn3.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in ResNet  

backbone.layer4.2.bn3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

head.fc.weight - torch.Size([17, 2048]): 
NormalInit: mean=0, std=0.01, bias=0 

head.fc.bias - torch.Size([17]): 
NormalInit: mean=0, std=0.01, bias=0 
2024-03-20 19:08:54,332 - mmcls - INFO - Start running, host: zaychan@gpu2-comp-110, work_dir: /userhome/cs2/zaychan/COMP3340Project/CNN_Image_Classification_Code/output/dataaugment/resnet50_flowers_bs16_randrotate
2024-03-20 19:08:54,333 - mmcls - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(NORMAL      ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2024-03-20 19:08:54,333 - mmcls - INFO - workflow: [('train', 1)], max: 200 epochs
2024-03-20 19:08:54,334 - mmcls - INFO - Checkpoints will be saved to /userhome/cs2/zaychan/COMP3340Project/CNN_Image_Classification_Code/output/dataaugment/resnet50_flowers_bs16_randrotate by HardDiskBackend.
2024-03-20 19:10:03,290 - mmcls - INFO - Epoch(val) [1][9]	accuracy_top-1: 14.7059, accuracy_top-5: 56.6176
2024-03-20 19:10:18,085 - mmcls - INFO - Epoch(val) [2][9]	accuracy_top-1: 11.0294, accuracy_top-5: 56.6176
2024-03-20 19:10:32,636 - mmcls - INFO - Epoch(val) [3][9]	accuracy_top-1: 14.7059, accuracy_top-5: 64.7059
2024-03-20 19:10:47,156 - mmcls - INFO - Epoch(val) [4][9]	accuracy_top-1: 25.7353, accuracy_top-5: 80.1471
2024-03-20 19:11:01,792 - mmcls - INFO - Epoch(val) [5][9]	accuracy_top-1: 20.5882, accuracy_top-5: 71.3235
2024-03-20 19:11:16,262 - mmcls - INFO - Epoch(val) [6][9]	accuracy_top-1: 31.6176, accuracy_top-5: 88.9706
2024-03-20 19:11:29,680 - mmcls - INFO - Epoch(val) [7][9]	accuracy_top-1: 43.3824, accuracy_top-5: 88.2353
2024-03-20 19:11:43,075 - mmcls - INFO - Epoch(val) [8][9]	accuracy_top-1: 44.1176, accuracy_top-5: 93.3824
2024-03-20 19:11:56,340 - mmcls - INFO - Epoch(val) [9][9]	accuracy_top-1: 38.9706, accuracy_top-5: 88.9706
2024-03-20 19:12:10,128 - mmcls - INFO - Epoch(val) [10][9]	accuracy_top-1: 41.1765, accuracy_top-5: 89.7059
2024-03-20 19:12:23,566 - mmcls - INFO - Epoch(val) [11][9]	accuracy_top-1: 38.9706, accuracy_top-5: 88.9706
2024-03-20 19:12:37,883 - mmcls - INFO - Epoch(val) [12][9]	accuracy_top-1: 45.5882, accuracy_top-5: 92.6471
2024-03-20 19:12:51,567 - mmcls - INFO - Epoch(val) [13][9]	accuracy_top-1: 55.1471, accuracy_top-5: 90.4412
2024-03-20 19:13:05,107 - mmcls - INFO - Epoch(val) [14][9]	accuracy_top-1: 59.5588, accuracy_top-5: 95.5882
2024-03-20 19:13:18,548 - mmcls - INFO - Epoch(val) [15][9]	accuracy_top-1: 55.1471, accuracy_top-5: 91.9118
2024-03-20 19:13:32,195 - mmcls - INFO - Epoch(val) [16][9]	accuracy_top-1: 50.7353, accuracy_top-5: 94.8529
2024-03-20 19:13:45,818 - mmcls - INFO - Epoch(val) [17][9]	accuracy_top-1: 59.5588, accuracy_top-5: 93.3824
2024-03-20 19:13:59,638 - mmcls - INFO - Epoch(val) [18][9]	accuracy_top-1: 59.5588, accuracy_top-5: 92.6471
2024-03-20 19:14:13,409 - mmcls - INFO - Epoch(val) [19][9]	accuracy_top-1: 56.6176, accuracy_top-5: 89.7059
2024-03-20 19:14:27,486 - mmcls - INFO - Epoch(val) [20][9]	accuracy_top-1: 53.6765, accuracy_top-5: 91.9118
2024-03-20 19:14:41,108 - mmcls - INFO - Epoch(val) [21][9]	accuracy_top-1: 55.1471, accuracy_top-5: 92.6471
2024-03-20 19:14:55,018 - mmcls - INFO - Epoch(val) [22][9]	accuracy_top-1: 57.3529, accuracy_top-5: 91.9118
2024-03-20 19:15:08,917 - mmcls - INFO - Epoch(val) [23][9]	accuracy_top-1: 58.0882, accuracy_top-5: 94.8529
2024-03-20 19:15:22,952 - mmcls - INFO - Epoch(val) [24][9]	accuracy_top-1: 55.8824, accuracy_top-5: 93.3824
2024-03-20 19:15:36,973 - mmcls - INFO - Epoch(val) [25][9]	accuracy_top-1: 69.1176, accuracy_top-5: 97.0588
2024-03-20 19:15:50,912 - mmcls - INFO - Epoch(val) [26][9]	accuracy_top-1: 63.9706, accuracy_top-5: 95.5882
2024-03-20 19:16:04,887 - mmcls - INFO - Epoch(val) [27][9]	accuracy_top-1: 62.5000, accuracy_top-5: 97.7941
2024-03-20 19:16:18,353 - mmcls - INFO - Epoch(val) [28][9]	accuracy_top-1: 67.6471, accuracy_top-5: 97.7941
2024-03-20 19:16:32,139 - mmcls - INFO - Epoch(val) [29][9]	accuracy_top-1: 57.3529, accuracy_top-5: 91.9118
2024-03-20 19:16:45,630 - mmcls - INFO - Epoch(val) [30][9]	accuracy_top-1: 60.2941, accuracy_top-5: 93.3824
2024-03-20 19:16:59,304 - mmcls - INFO - Epoch(val) [31][9]	accuracy_top-1: 69.1176, accuracy_top-5: 95.5882
2024-03-20 19:17:13,659 - mmcls - INFO - Epoch(val) [32][9]	accuracy_top-1: 68.3824, accuracy_top-5: 94.1176
2024-03-20 19:17:28,319 - mmcls - INFO - Epoch(val) [33][9]	accuracy_top-1: 63.2353, accuracy_top-5: 95.5882
2024-03-20 19:17:42,201 - mmcls - INFO - Epoch(val) [34][9]	accuracy_top-1: 70.5882, accuracy_top-5: 97.7941
2024-03-20 19:17:56,210 - mmcls - INFO - Epoch(val) [35][9]	accuracy_top-1: 66.1765, accuracy_top-5: 94.8529
2024-03-20 19:18:10,503 - mmcls - INFO - Epoch(val) [36][9]	accuracy_top-1: 66.1765, accuracy_top-5: 93.3824
2024-03-20 19:18:24,662 - mmcls - INFO - Epoch(val) [37][9]	accuracy_top-1: 67.6471, accuracy_top-5: 97.7941
2024-03-20 19:18:38,462 - mmcls - INFO - Epoch(val) [38][9]	accuracy_top-1: 69.1176, accuracy_top-5: 94.1176
2024-03-20 19:18:52,180 - mmcls - INFO - Epoch(val) [39][9]	accuracy_top-1: 73.5294, accuracy_top-5: 95.5882
2024-03-20 19:19:05,811 - mmcls - INFO - Epoch(val) [40][9]	accuracy_top-1: 61.0294, accuracy_top-5: 98.5294
2024-03-20 19:19:19,964 - mmcls - INFO - Epoch(val) [41][9]	accuracy_top-1: 72.0588, accuracy_top-5: 94.8529
2024-03-20 19:19:33,961 - mmcls - INFO - Epoch(val) [42][9]	accuracy_top-1: 75.0000, accuracy_top-5: 97.0588
2024-03-20 19:19:48,455 - mmcls - INFO - Epoch(val) [43][9]	accuracy_top-1: 64.7059, accuracy_top-5: 98.5294
2024-03-20 19:20:02,522 - mmcls - INFO - Epoch(val) [44][9]	accuracy_top-1: 71.3235, accuracy_top-5: 95.5882
2024-03-20 19:20:16,816 - mmcls - INFO - Epoch(val) [45][9]	accuracy_top-1: 69.8529, accuracy_top-5: 93.3824
2024-03-20 19:20:30,810 - mmcls - INFO - Epoch(val) [46][9]	accuracy_top-1: 73.5294, accuracy_top-5: 97.0588
2024-03-20 19:20:44,800 - mmcls - INFO - Epoch(val) [47][9]	accuracy_top-1: 69.8529, accuracy_top-5: 96.3235
2024-03-20 19:20:58,739 - mmcls - INFO - Epoch(val) [48][9]	accuracy_top-1: 71.3235, accuracy_top-5: 95.5882
2024-03-20 19:21:12,712 - mmcls - INFO - Epoch(val) [49][9]	accuracy_top-1: 66.1765, accuracy_top-5: 96.3235
2024-03-20 19:21:26,919 - mmcls - INFO - Epoch(val) [50][9]	accuracy_top-1: 72.0588, accuracy_top-5: 95.5882
2024-03-20 19:21:41,052 - mmcls - INFO - Epoch(val) [51][9]	accuracy_top-1: 77.2059, accuracy_top-5: 96.3235
2024-03-20 19:21:55,332 - mmcls - INFO - Epoch(val) [52][9]	accuracy_top-1: 75.0000, accuracy_top-5: 96.3235
2024-03-20 19:22:10,255 - mmcls - INFO - Epoch(val) [53][9]	accuracy_top-1: 66.9118, accuracy_top-5: 93.3824
2024-03-20 19:22:24,843 - mmcls - INFO - Epoch(val) [54][9]	accuracy_top-1: 70.5882, accuracy_top-5: 94.1176
2024-03-20 19:22:39,099 - mmcls - INFO - Epoch(val) [55][9]	accuracy_top-1: 72.7941, accuracy_top-5: 98.5294
2024-03-20 19:22:53,943 - mmcls - INFO - Epoch(val) [56][9]	accuracy_top-1: 62.5000, accuracy_top-5: 94.8529
2024-03-20 19:23:08,266 - mmcls - INFO - Epoch(val) [57][9]	accuracy_top-1: 74.2647, accuracy_top-5: 97.0588
2024-03-20 19:23:22,714 - mmcls - INFO - Epoch(val) [58][9]	accuracy_top-1: 80.1471, accuracy_top-5: 100.0000
2024-03-20 19:23:36,833 - mmcls - INFO - Epoch(val) [59][9]	accuracy_top-1: 70.5882, accuracy_top-5: 97.7941
2024-03-20 19:23:50,396 - mmcls - INFO - Epoch(val) [60][9]	accuracy_top-1: 79.4118, accuracy_top-5: 96.3235
2024-03-20 19:24:04,005 - mmcls - INFO - Epoch(val) [61][9]	accuracy_top-1: 72.0588, accuracy_top-5: 95.5882
2024-03-20 19:24:17,736 - mmcls - INFO - Epoch(val) [62][9]	accuracy_top-1: 69.1176, accuracy_top-5: 94.8529
2024-03-20 19:24:31,607 - mmcls - INFO - Epoch(val) [63][9]	accuracy_top-1: 71.3235, accuracy_top-5: 97.0588
2024-03-20 19:24:46,259 - mmcls - INFO - Epoch(val) [64][9]	accuracy_top-1: 74.2647, accuracy_top-5: 98.5294
2024-03-20 19:25:00,140 - mmcls - INFO - Epoch(val) [65][9]	accuracy_top-1: 77.2059, accuracy_top-5: 98.5294
2024-03-20 19:25:13,901 - mmcls - INFO - Epoch(val) [66][9]	accuracy_top-1: 72.7941, accuracy_top-5: 96.3235
2024-03-20 19:25:28,144 - mmcls - INFO - Epoch(val) [67][9]	accuracy_top-1: 80.1471, accuracy_top-5: 97.7941
2024-03-20 19:25:42,211 - mmcls - INFO - Epoch(val) [68][9]	accuracy_top-1: 78.6765, accuracy_top-5: 97.0588
2024-03-20 19:25:56,225 - mmcls - INFO - Epoch(val) [69][9]	accuracy_top-1: 73.5294, accuracy_top-5: 97.0588
2024-03-20 19:26:10,190 - mmcls - INFO - Epoch(val) [70][9]	accuracy_top-1: 76.4706, accuracy_top-5: 98.5294
2024-03-20 19:26:23,780 - mmcls - INFO - Epoch(val) [71][9]	accuracy_top-1: 69.8529, accuracy_top-5: 95.5882
2024-03-20 19:26:38,144 - mmcls - INFO - Epoch(val) [72][9]	accuracy_top-1: 75.7353, accuracy_top-5: 99.2647
2024-03-20 19:26:52,107 - mmcls - INFO - Epoch(val) [73][9]	accuracy_top-1: 76.4706, accuracy_top-5: 98.5294
2024-03-20 19:27:06,157 - mmcls - INFO - Epoch(val) [74][9]	accuracy_top-1: 80.1471, accuracy_top-5: 97.7941
2024-03-20 19:27:20,120 - mmcls - INFO - Epoch(val) [75][9]	accuracy_top-1: 79.4118, accuracy_top-5: 94.1176
2024-03-20 19:27:33,509 - mmcls - INFO - Epoch(val) [76][9]	accuracy_top-1: 79.4118, accuracy_top-5: 96.3235
2024-03-20 19:27:47,433 - mmcls - INFO - Epoch(val) [77][9]	accuracy_top-1: 77.2059, accuracy_top-5: 98.5294
2024-03-20 19:28:01,905 - mmcls - INFO - Epoch(val) [78][9]	accuracy_top-1: 77.9412, accuracy_top-5: 96.3235
2024-03-20 19:28:17,073 - mmcls - INFO - Epoch(val) [79][9]	accuracy_top-1: 80.8824, accuracy_top-5: 98.5294
2024-03-20 19:28:31,702 - mmcls - INFO - Epoch(val) [80][9]	accuracy_top-1: 79.4118, accuracy_top-5: 97.0588
2024-03-20 19:28:46,396 - mmcls - INFO - Epoch(val) [81][9]	accuracy_top-1: 77.2059, accuracy_top-5: 95.5882
2024-03-20 19:29:00,309 - mmcls - INFO - Epoch(val) [82][9]	accuracy_top-1: 74.2647, accuracy_top-5: 97.7941
2024-03-20 19:29:14,220 - mmcls - INFO - Epoch(val) [83][9]	accuracy_top-1: 75.7353, accuracy_top-5: 98.5294
2024-03-20 19:29:28,144 - mmcls - INFO - Epoch(val) [84][9]	accuracy_top-1: 76.4706, accuracy_top-5: 98.5294
2024-03-20 19:29:42,034 - mmcls - INFO - Epoch(val) [85][9]	accuracy_top-1: 74.2647, accuracy_top-5: 100.0000
2024-03-20 19:29:55,703 - mmcls - INFO - Epoch(val) [86][9]	accuracy_top-1: 68.3824, accuracy_top-5: 97.0588
2024-03-20 19:30:09,511 - mmcls - INFO - Epoch(val) [87][9]	accuracy_top-1: 73.5294, accuracy_top-5: 97.7941
2024-03-20 19:30:23,532 - mmcls - INFO - Epoch(val) [88][9]	accuracy_top-1: 75.7353, accuracy_top-5: 97.0588
2024-03-20 19:30:37,446 - mmcls - INFO - Epoch(val) [89][9]	accuracy_top-1: 78.6765, accuracy_top-5: 96.3235
2024-03-20 19:30:51,379 - mmcls - INFO - Epoch(val) [90][9]	accuracy_top-1: 77.2059, accuracy_top-5: 97.0588
2024-03-20 19:31:05,378 - mmcls - INFO - Epoch(val) [91][9]	accuracy_top-1: 77.2059, accuracy_top-5: 99.2647
2024-03-20 19:31:19,160 - mmcls - INFO - Epoch(val) [92][9]	accuracy_top-1: 76.4706, accuracy_top-5: 98.5294
2024-03-20 19:31:32,763 - mmcls - INFO - Epoch(val) [93][9]	accuracy_top-1: 69.1176, accuracy_top-5: 97.7941
2024-03-20 19:31:46,511 - mmcls - INFO - Epoch(val) [94][9]	accuracy_top-1: 79.4118, accuracy_top-5: 99.2647
2024-03-20 19:32:00,133 - mmcls - INFO - Epoch(val) [95][9]	accuracy_top-1: 84.5588, accuracy_top-5: 98.5294
2024-03-20 19:32:13,795 - mmcls - INFO - Epoch(val) [96][9]	accuracy_top-1: 78.6765, accuracy_top-5: 95.5882
2024-03-20 19:32:27,741 - mmcls - INFO - Epoch(val) [97][9]	accuracy_top-1: 82.3529, accuracy_top-5: 100.0000
2024-03-20 19:32:41,351 - mmcls - INFO - Epoch(val) [98][9]	accuracy_top-1: 83.8235, accuracy_top-5: 99.2647
2024-03-20 19:32:55,526 - mmcls - INFO - Epoch(val) [99][9]	accuracy_top-1: 79.4118, accuracy_top-5: 97.7941
2024-03-20 19:33:08,397 - mmcls - INFO - Saving checkpoint at 100 epochs
2024-03-20 19:33:10,655 - mmcls - INFO - Epoch(val) [100][9]	accuracy_top-1: 87.5000, accuracy_top-5: 98.5294
2024-03-20 19:33:24,756 - mmcls - INFO - Epoch(val) [101][9]	accuracy_top-1: 89.7059, accuracy_top-5: 100.0000
2024-03-20 19:33:39,056 - mmcls - INFO - Epoch(val) [102][9]	accuracy_top-1: 87.5000, accuracy_top-5: 100.0000
2024-03-20 19:33:52,856 - mmcls - INFO - Epoch(val) [103][9]	accuracy_top-1: 86.7647, accuracy_top-5: 100.0000
2024-03-20 19:34:06,709 - mmcls - INFO - Epoch(val) [104][9]	accuracy_top-1: 87.5000, accuracy_top-5: 100.0000
2024-03-20 19:34:20,130 - mmcls - INFO - Epoch(val) [105][9]	accuracy_top-1: 88.2353, accuracy_top-5: 100.0000
2024-03-20 19:34:33,774 - mmcls - INFO - Epoch(val) [106][9]	accuracy_top-1: 86.7647, accuracy_top-5: 100.0000
2024-03-20 19:34:47,290 - mmcls - INFO - Epoch(val) [107][9]	accuracy_top-1: 87.5000, accuracy_top-5: 100.0000
2024-03-20 19:35:00,709 - mmcls - INFO - Epoch(val) [108][9]	accuracy_top-1: 88.9706, accuracy_top-5: 100.0000
2024-03-20 19:35:13,860 - mmcls - INFO - Epoch(val) [109][9]	accuracy_top-1: 87.5000, accuracy_top-5: 100.0000
2024-03-20 19:35:27,360 - mmcls - INFO - Epoch(val) [110][9]	accuracy_top-1: 90.4412, accuracy_top-5: 100.0000
2024-03-20 19:35:41,061 - mmcls - INFO - Epoch(val) [111][9]	accuracy_top-1: 88.9706, accuracy_top-5: 100.0000
2024-03-20 19:35:54,727 - mmcls - INFO - Epoch(val) [112][9]	accuracy_top-1: 88.9706, accuracy_top-5: 100.0000
2024-03-20 19:36:08,180 - mmcls - INFO - Epoch(val) [113][9]	accuracy_top-1: 89.7059, accuracy_top-5: 100.0000
2024-03-20 19:36:21,794 - mmcls - INFO - Epoch(val) [114][9]	accuracy_top-1: 88.2353, accuracy_top-5: 100.0000
2024-03-20 19:36:35,401 - mmcls - INFO - Epoch(val) [115][9]	accuracy_top-1: 85.2941, accuracy_top-5: 100.0000
2024-03-20 19:36:48,907 - mmcls - INFO - Epoch(val) [116][9]	accuracy_top-1: 86.0294, accuracy_top-5: 100.0000
2024-03-20 19:37:02,501 - mmcls - INFO - Epoch(val) [117][9]	accuracy_top-1: 88.2353, accuracy_top-5: 99.2647
2024-03-20 19:37:16,044 - mmcls - INFO - Epoch(val) [118][9]	accuracy_top-1: 86.0294, accuracy_top-5: 99.2647
2024-03-20 19:37:29,542 - mmcls - INFO - Epoch(val) [119][9]	accuracy_top-1: 87.5000, accuracy_top-5: 99.2647
2024-03-20 19:37:43,133 - mmcls - INFO - Epoch(val) [120][9]	accuracy_top-1: 87.5000, accuracy_top-5: 99.2647
2024-03-20 19:37:56,892 - mmcls - INFO - Epoch(val) [121][9]	accuracy_top-1: 85.2941, accuracy_top-5: 99.2647
2024-03-20 19:38:10,317 - mmcls - INFO - Epoch(val) [122][9]	accuracy_top-1: 85.2941, accuracy_top-5: 100.0000
2024-03-20 19:38:23,897 - mmcls - INFO - Epoch(val) [123][9]	accuracy_top-1: 86.0294, accuracy_top-5: 100.0000
2024-03-20 19:38:37,515 - mmcls - INFO - Epoch(val) [124][9]	accuracy_top-1: 86.0294, accuracy_top-5: 100.0000
2024-03-20 19:38:51,512 - mmcls - INFO - Epoch(val) [125][9]	accuracy_top-1: 86.7647, accuracy_top-5: 100.0000
2024-03-20 19:39:05,515 - mmcls - INFO - Epoch(val) [126][9]	accuracy_top-1: 88.9706, accuracy_top-5: 100.0000
2024-03-20 19:39:19,089 - mmcls - INFO - Epoch(val) [127][9]	accuracy_top-1: 87.5000, accuracy_top-5: 100.0000
2024-03-20 19:39:32,599 - mmcls - INFO - Epoch(val) [128][9]	accuracy_top-1: 85.2941, accuracy_top-5: 100.0000
2024-03-20 19:39:46,197 - mmcls - INFO - Epoch(val) [129][9]	accuracy_top-1: 85.2941, accuracy_top-5: 100.0000
2024-03-20 19:39:59,759 - mmcls - INFO - Epoch(val) [130][9]	accuracy_top-1: 86.7647, accuracy_top-5: 99.2647
2024-03-20 19:40:13,419 - mmcls - INFO - Epoch(val) [131][9]	accuracy_top-1: 88.2353, accuracy_top-5: 98.5294
2024-03-20 19:40:26,730 - mmcls - INFO - Epoch(val) [132][9]	accuracy_top-1: 88.2353, accuracy_top-5: 99.2647
2024-03-20 19:40:40,204 - mmcls - INFO - Epoch(val) [133][9]	accuracy_top-1: 86.7647, accuracy_top-5: 100.0000
2024-03-20 19:40:53,489 - mmcls - INFO - Epoch(val) [134][9]	accuracy_top-1: 86.7647, accuracy_top-5: 100.0000
2024-03-20 19:41:06,954 - mmcls - INFO - Epoch(val) [135][9]	accuracy_top-1: 88.9706, accuracy_top-5: 100.0000
2024-03-20 19:41:20,913 - mmcls - INFO - Epoch(val) [136][9]	accuracy_top-1: 88.9706, accuracy_top-5: 100.0000
2024-03-20 19:41:34,398 - mmcls - INFO - Epoch(val) [137][9]	accuracy_top-1: 88.9706, accuracy_top-5: 99.2647
2024-03-20 19:41:48,080 - mmcls - INFO - Epoch(val) [138][9]	accuracy_top-1: 88.2353, accuracy_top-5: 100.0000
2024-03-20 19:42:01,845 - mmcls - INFO - Epoch(val) [139][9]	accuracy_top-1: 88.9706, accuracy_top-5: 100.0000
2024-03-20 19:42:15,650 - mmcls - INFO - Epoch(val) [140][9]	accuracy_top-1: 87.5000, accuracy_top-5: 100.0000
2024-03-20 19:42:29,404 - mmcls - INFO - Epoch(val) [141][9]	accuracy_top-1: 88.9706, accuracy_top-5: 100.0000
2024-03-20 19:42:43,708 - mmcls - INFO - Epoch(val) [142][9]	accuracy_top-1: 90.4412, accuracy_top-5: 99.2647
2024-03-20 19:42:57,241 - mmcls - INFO - Epoch(val) [143][9]	accuracy_top-1: 86.0294, accuracy_top-5: 100.0000
2024-03-20 19:43:10,517 - mmcls - INFO - Epoch(val) [144][9]	accuracy_top-1: 88.2353, accuracy_top-5: 100.0000
2024-03-20 19:43:24,327 - mmcls - INFO - Epoch(val) [145][9]	accuracy_top-1: 89.7059, accuracy_top-5: 99.2647
2024-03-20 19:43:37,818 - mmcls - INFO - Epoch(val) [146][9]	accuracy_top-1: 86.0294, accuracy_top-5: 100.0000
2024-03-20 19:43:51,259 - mmcls - INFO - Epoch(val) [147][9]	accuracy_top-1: 87.5000, accuracy_top-5: 100.0000
2024-03-20 19:44:04,742 - mmcls - INFO - Epoch(val) [148][9]	accuracy_top-1: 87.5000, accuracy_top-5: 99.2647
2024-03-20 19:44:18,293 - mmcls - INFO - Epoch(val) [149][9]	accuracy_top-1: 86.7647, accuracy_top-5: 100.0000
2024-03-20 19:44:32,068 - mmcls - INFO - Epoch(val) [150][9]	accuracy_top-1: 88.9706, accuracy_top-5: 100.0000
2024-03-20 19:44:45,357 - mmcls - INFO - Epoch(val) [151][9]	accuracy_top-1: 86.0294, accuracy_top-5: 99.2647
2024-03-20 19:44:58,712 - mmcls - INFO - Epoch(val) [152][9]	accuracy_top-1: 88.2353, accuracy_top-5: 99.2647
2024-03-20 19:45:12,037 - mmcls - INFO - Epoch(val) [153][9]	accuracy_top-1: 88.9706, accuracy_top-5: 99.2647
2024-03-20 19:45:25,770 - mmcls - INFO - Epoch(val) [154][9]	accuracy_top-1: 88.9706, accuracy_top-5: 99.2647
2024-03-20 19:45:39,631 - mmcls - INFO - Epoch(val) [155][9]	accuracy_top-1: 88.9706, accuracy_top-5: 99.2647
2024-03-20 19:45:53,192 - mmcls - INFO - Epoch(val) [156][9]	accuracy_top-1: 88.2353, accuracy_top-5: 100.0000
2024-03-20 19:46:07,089 - mmcls - INFO - Epoch(val) [157][9]	accuracy_top-1: 88.9706, accuracy_top-5: 100.0000
2024-03-20 19:46:20,221 - mmcls - INFO - Epoch(val) [158][9]	accuracy_top-1: 88.2353, accuracy_top-5: 99.2647
2024-03-20 19:46:33,878 - mmcls - INFO - Epoch(val) [159][9]	accuracy_top-1: 88.9706, accuracy_top-5: 100.0000
2024-03-20 19:46:47,345 - mmcls - INFO - Epoch(val) [160][9]	accuracy_top-1: 88.2353, accuracy_top-5: 100.0000
2024-03-20 19:47:00,790 - mmcls - INFO - Epoch(val) [161][9]	accuracy_top-1: 87.5000, accuracy_top-5: 100.0000
2024-03-20 19:47:14,338 - mmcls - INFO - Epoch(val) [162][9]	accuracy_top-1: 86.7647, accuracy_top-5: 100.0000
2024-03-20 19:47:27,635 - mmcls - INFO - Epoch(val) [163][9]	accuracy_top-1: 86.7647, accuracy_top-5: 100.0000
2024-03-20 19:47:41,324 - mmcls - INFO - Epoch(val) [164][9]	accuracy_top-1: 86.7647, accuracy_top-5: 100.0000
2024-03-20 19:47:54,897 - mmcls - INFO - Epoch(val) [165][9]	accuracy_top-1: 87.5000, accuracy_top-5: 100.0000
2024-03-20 19:48:08,234 - mmcls - INFO - Epoch(val) [166][9]	accuracy_top-1: 86.0294, accuracy_top-5: 100.0000
2024-03-20 19:48:21,784 - mmcls - INFO - Epoch(val) [167][9]	accuracy_top-1: 88.2353, accuracy_top-5: 100.0000
2024-03-20 19:48:35,362 - mmcls - INFO - Epoch(val) [168][9]	accuracy_top-1: 86.7647, accuracy_top-5: 99.2647
2024-03-20 19:48:49,139 - mmcls - INFO - Epoch(val) [169][9]	accuracy_top-1: 86.7647, accuracy_top-5: 99.2647
2024-03-20 19:49:02,595 - mmcls - INFO - Epoch(val) [170][9]	accuracy_top-1: 87.5000, accuracy_top-5: 100.0000
2024-03-20 19:49:16,120 - mmcls - INFO - Epoch(val) [171][9]	accuracy_top-1: 86.7647, accuracy_top-5: 99.2647
2024-03-20 19:49:29,685 - mmcls - INFO - Epoch(val) [172][9]	accuracy_top-1: 87.5000, accuracy_top-5: 100.0000
2024-03-20 19:49:43,221 - mmcls - INFO - Epoch(val) [173][9]	accuracy_top-1: 88.2353, accuracy_top-5: 100.0000
2024-03-20 19:49:56,778 - mmcls - INFO - Epoch(val) [174][9]	accuracy_top-1: 86.7647, accuracy_top-5: 99.2647
2024-03-20 19:50:10,538 - mmcls - INFO - Epoch(val) [175][9]	accuracy_top-1: 87.5000, accuracy_top-5: 100.0000
2024-03-20 19:50:24,057 - mmcls - INFO - Epoch(val) [176][9]	accuracy_top-1: 87.5000, accuracy_top-5: 99.2647
2024-03-20 19:50:37,612 - mmcls - INFO - Epoch(val) [177][9]	accuracy_top-1: 87.5000, accuracy_top-5: 100.0000
2024-03-20 19:50:50,864 - mmcls - INFO - Epoch(val) [178][9]	accuracy_top-1: 86.0294, accuracy_top-5: 99.2647
2024-03-20 19:51:04,525 - mmcls - INFO - Epoch(val) [179][9]	accuracy_top-1: 86.7647, accuracy_top-5: 99.2647
2024-03-20 19:51:18,179 - mmcls - INFO - Epoch(val) [180][9]	accuracy_top-1: 87.5000, accuracy_top-5: 99.2647
2024-03-20 19:51:32,133 - mmcls - INFO - Epoch(val) [181][9]	accuracy_top-1: 86.7647, accuracy_top-5: 100.0000
2024-03-20 19:51:46,045 - mmcls - INFO - Epoch(val) [182][9]	accuracy_top-1: 86.7647, accuracy_top-5: 100.0000
2024-03-20 19:52:00,649 - mmcls - INFO - Epoch(val) [183][9]	accuracy_top-1: 88.2353, accuracy_top-5: 100.0000
2024-03-20 19:52:14,508 - mmcls - INFO - Epoch(val) [184][9]	accuracy_top-1: 86.7647, accuracy_top-5: 100.0000
2024-03-20 19:52:28,192 - mmcls - INFO - Epoch(val) [185][9]	accuracy_top-1: 86.0294, accuracy_top-5: 100.0000
2024-03-20 19:52:41,978 - mmcls - INFO - Epoch(val) [186][9]	accuracy_top-1: 86.7647, accuracy_top-5: 100.0000
2024-03-20 19:52:55,588 - mmcls - INFO - Epoch(val) [187][9]	accuracy_top-1: 86.7647, accuracy_top-5: 99.2647
2024-03-20 19:53:09,316 - mmcls - INFO - Epoch(val) [188][9]	accuracy_top-1: 87.5000, accuracy_top-5: 100.0000
2024-03-20 19:53:22,915 - mmcls - INFO - Epoch(val) [189][9]	accuracy_top-1: 87.5000, accuracy_top-5: 99.2647
2024-03-20 19:53:36,561 - mmcls - INFO - Epoch(val) [190][9]	accuracy_top-1: 86.7647, accuracy_top-5: 100.0000
2024-03-20 19:53:50,500 - mmcls - INFO - Epoch(val) [191][9]	accuracy_top-1: 87.5000, accuracy_top-5: 99.2647
2024-03-20 19:54:04,195 - mmcls - INFO - Epoch(val) [192][9]	accuracy_top-1: 88.9706, accuracy_top-5: 99.2647
2024-03-20 19:54:18,067 - mmcls - INFO - Epoch(val) [193][9]	accuracy_top-1: 87.5000, accuracy_top-5: 100.0000
2024-03-20 19:54:31,582 - mmcls - INFO - Epoch(val) [194][9]	accuracy_top-1: 87.5000, accuracy_top-5: 100.0000
2024-03-20 19:54:45,299 - mmcls - INFO - Epoch(val) [195][9]	accuracy_top-1: 88.2353, accuracy_top-5: 100.0000
2024-03-20 19:54:59,164 - mmcls - INFO - Epoch(val) [196][9]	accuracy_top-1: 88.2353, accuracy_top-5: 100.0000
2024-03-20 19:55:12,961 - mmcls - INFO - Epoch(val) [197][9]	accuracy_top-1: 88.2353, accuracy_top-5: 100.0000
2024-03-20 19:55:26,140 - mmcls - INFO - Epoch(val) [198][9]	accuracy_top-1: 86.7647, accuracy_top-5: 99.2647
2024-03-20 19:55:39,761 - mmcls - INFO - Epoch(val) [199][9]	accuracy_top-1: 87.5000, accuracy_top-5: 100.0000
2024-03-20 19:55:52,018 - mmcls - INFO - Saving checkpoint at 200 epochs
2024-03-20 19:55:54,320 - mmcls - INFO - Epoch(val) [200][9]	accuracy_top-1: 88.2353, accuracy_top-5: 100.0000
